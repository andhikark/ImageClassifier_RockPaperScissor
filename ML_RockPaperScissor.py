# -*- coding: utf-8 -*-
"""Andhika_Dicoding

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZDATpvYYrhKhJAFWGt0lBNSPQBVW954f

# andhikaa_restu
"""

#import tensorflow
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Conv2D, Activation, Flatten, MaxPool2D
from tensorflow.keras.utils import load_img

#Print tensorflow version
print(tf.__version__)

#download dataset
!wget https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip

#Install split folders
!pip install split_folders

import zipfile,os
import splitfolders

local_zip = 'rockpaperscissors.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('rps')
zip_ref.close()

splitfolders.ratio('rps/rockpaperscissors/rps-cv-images', output="rps/rockpaperscissors/data", seed=1337, ratio=(.6, .4))



data_dir = 'rps/rockpaperscissors/data'
train_dir = os.path.join(data_dir, 'train')
validation_dir = os.path.join(data_dir, 'val')

os.listdir('rps/rockpaperscissors/data/train')
os.listdir('rps/rockpaperscissors/data/val')

print(len(os.listdir('rps/rockpaperscissors/paper')))
print(len(os.listdir('rps/rockpaperscissors/scissors')))
print(len(os.listdir('rps/rockpaperscissors/rock')))

train_paper_dir = os.path.join(train_dir, 'paper')
train_scissors_dir = os.path.join(train_dir, 'scissors')
train_rock_dir = os.path.join(train_dir, 'rock')

validation_paper_dir = os.path.join(validation_dir, 'paper')
validation_scissors_dir = os.path.join(validation_dir, 'scissors')
validation_rock_dir = os.path.join(validation_dir, 'rock')

paper_imgs = os.listdir(train_paper_dir)
scissors_imgs = os.listdir(train_scissors_dir)
rock_imgs = os.listdir(train_rock_dir)

import matplotlib.pyplot as plt
import matplotlib.image as mpimg

plt.figure(figsize=(22, 5))
for i, img_path in enumerate(paper_imgs[:5]):
  sp = plt.subplot(1, 5, i+1)
  img = mpimg.imread(os.path.join(train_paper_dir, img_path))
  plt.imshow(img)
plt.show()

plt.figure(figsize=(22, 5))
for i, img_path in enumerate(scissors_imgs[:5]):
  sp = plt.subplot(1, 5, i+1)
  img = mpimg.imread(os.path.join(train_scissors_dir, img_path))
  plt.imshow(img)
plt.show()

plt.figure(figsize=(22, 5))
for i, img_path in enumerate(rock_imgs[:5]):
  sp = plt.subplot(1, 5, i+1)
  img = mpimg.imread(os.path.join(train_rock_dir, img_path))
  plt.imshow(img)
plt.show()

train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.9999, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)
validation_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.9999)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size = (100, 100),
    batch_size = 32,
    class_mode = 'categorical',
    color_mode = 'rgb',
    shuffle = True
)

valid_generator = validation_datagen.flow_from_directory(
    validation_dir,
    target_size = (100, 100),
    batch_size = 32,
    class_mode = 'categorical',
    color_mode = 'rgb',
    shuffle = True,
)

train_generator.class_indices

valid_generator.class_indices

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(100, 100, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Dropout(0.25),
    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Dropout(0.25),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Dropout(0.25),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Dropout(0.25),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')
])

model.summary()

model.compile(loss = 'categorical_crossentropy',
              optimizer= 'RMSprop', 
              metrics= ['accuracy'])

historyku = model.fit(train_generator, 
          steps_per_epoch=25, 
          epochs=20, 
          validation_data=valid_generator,
          validation_steps=5,
          verbose=2)

import matplotlib.pyplot as plt

acc = historyku.history['accuracy']
val_acc = historyku.history['val_accuracy']

loss = historyku.history['loss']
val_loss = historyku.history['val_loss']

plt.plot(acc, color='blue')
plt.plot(val_acc, color='red')
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

plt.plot(loss, color='blue')
plt.plot(val_loss, color='red')
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
from google.colab import files
from keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline

uploaded = files.upload()

for fn in uploaded.keys():

    path = fn
    img = tf.keras.utils.load_img(path, target_size=(100,100))
    imgplot = plt.imshow(img)
    x = tf.keras.utils.img_to_array(img)
    x = np.expand_dims(x, axis=0)
 
    images = np.vstack([x])
    classes = model.predict(images, batch_size=32)
  
    print(fn)
    if classes[0,0] == 1.0:
      print('Paper')
    elif classes[0,1] == 1.0:
      print('Rock')
    else:
      print('Scissors')
